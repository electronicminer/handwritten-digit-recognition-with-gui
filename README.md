# handwritten-digit-recognition-with-gui
Handwritten Digit Recognition | Python + Tkinter + PyTorch | MNIST CNN Model​

## 功能模块说明

- **模型训练**：`train.ipynb` 负责加载 MNIST 数据集并训练 CNN 模型，输出模型为 `digit_cnn.pth`。
- **模型识别**：
  - `digit_recognition.py`：加载模型并进行图像预处理和识别手写图像。
  - `digit_recognition.ipynb`：Notebook 形式展示图像识别流程（测试时使用）。
- **gui 测试**：`test.py` 
- **图形界面**：`app.py` 本课程设计的窗口 gui，打开本脚本以使用该程序图形化界面设计的图片识别和手写识别功能。详见后文
- **测试图像**：`test_image/` 中存放用于测试的图像样本。

# python手写数字识别系统课程设计


## 1. 需求分析

本系统设计的目标是实现一个实用且交互友好的手写数字识别工具。需求分析细化如下：

* **单张数字识别**：
  用户能够上传或绘制单个数字图像，系统需高效准确识别数字类别，适应不同书写风格。

* **多数字图像处理**：
  现实场景中，图像往往包含多个数字，系统需要实现自动检测、分割各个数字区域，并按书写顺序批量预测，保证识别的完整性与准确性。

* **图形用户界面交互**：
  设计直观的GUI，允许用户通过鼠标在画布自由书写，系统实时识别，提高用户体验。支持图片导入功能方便多样化操作。

* **实时自动识别**：
  画布绘制完成后，系统自动将图像送入预处理和模型识别模块，无需额外点击，提升交互智能化。

* **模型训练与评估支持**：
  支持模型的训练和测试模块，能够监控训练过程，输出模型性能指标，如准确率和混淆矩阵，便于调优。

* **可扩展的摄像头实时识别**：
  预留摄像头实时输入接口，未来可扩展为动态数字识别。

需求分析兼顾功能实用性与用户体验。


## 2. 总体框架设计

系统整体结构如图所示：

```
+-------------------+
|     用户界面      |  ← 用户输入（画板绘制/图片导入）
+-------------------+
           ↓
+---------------------------+
|      图像预处理模块       |  ← 灰度转换、对比度增强、二值化、裁剪、居中缩放
+---------------------------+
           ↓
+-------------------+
|    数字切割模块    |  ← 多数字图像分割，轮廓检测提取数字区域
+-------------------+
           ↓
+-------------------+
|    CNN识别模型    |  ← 基于PyTorch实现的卷积神经网络模型预测数字类别
+-------------------+
           ↓
+-------------------+
|    结果展示模块    |  ← 识别结果反馈给用户界面显示
+-------------------+

```

## 3. 功能详细设计

### 3.1 图像预处理(mnist_style_preprocess)
此函数将用户输入的手写数字或数字图像转化为minst数据集风格的图像，极大提高识别的准确度。

灰度转换：将输入彩色图像转换为单通道灰度图。

对比度增强：采用 PIL.ImageEnhance.Contrast 提高数字笔迹的清晰度，默认增强系数为 2.0。

二值化处理：通过设定阈值将图像转为黑白，去除背景噪声，突出数字形状。

裁剪数字区域：自动识别数字所在的最小矩形区域，裁剪后缩放到 20x20。

数字居中：将缩放后的数字粘贴到 28x28 黑底图像中心，使其符合 MNIST 数据格式标准。

### 3.2 数字切割(detect_digits_line)

识别含多个数字的图像时，使用 OpenCV 进行如下处理：

* 图像灰度转换与二值化处理；
* 使用 `cv2.findContours` 查找外轮廓；
* 过滤小区域，避免噪声干扰。
* 使用 `cv2.boundingRect` 获取最小外接矩形；
* 按照 x 坐标对所有矩形排序，从而获取数字的正确排列顺序；
* 对每个区域分别进行预处理后送入模型预测。

### 3.3 CNN模型

CNN 模型结构如下：

```
输入：1×28×28 灰度图
 ↓ Conv2d(1, 32, 3) + ReLU + MaxPool
 ↓ Conv2d(32, 64, 3) + ReLU + MaxPool
 ↓ Flatten → Linear(3136, 128) → Dropout(0.5) → ReLU
 ↓ Linear(128, 10) → 输出 10 类别概率
```
网络结构：

* **两层卷积层（Conv2d）**:分别使用 32 和 64 个 3x3 卷积核，提取图像中的边缘、轮廓等局部特征，前两层分别提取低级和高级特征，后接 ReLU 和最大池化。
  
* **激活函数（ReLU）**：引入非线性因素，提高模型表达能力；

* **池化层（MaxPooling）**：下采样特征图，减少计算量并增强模型对位移和噪声的鲁棒性；

* **两层全连接层**:第一层 128 个神经元带 Dropout，第二层输出10类数字概率。整合局部特征，实现全局分类判断。

* **Dropout 层**：在训练过程中随机屏蔽部分神经元，有效防止过拟合；

* **输出层**：最终输出 10 类概率分布，对应数字 0~9。
训练参数：

* **优化器**：Adam，学习率 0.05。

* **损失函数**：交叉熵(CrossEntropyLoss)。

模型使用 ReLU 激活函数和 Dropout 正则化以防止过拟合。

性能：最终模型在 MNIST 测试集上准确率达到 98.86%。



### 3.4 模型训练

训练使用 `train.py` 脚本实现，关键设计如下：

* 使用 MNIST 数据集进行训练与测试；
* 将图像转换为单通道灰度图；
* 将图像尺寸缩放到 28x28 像素。保持输入大小一致；
* 将图像从 PIL 或 numpy 格式转换为 PyTorch 的张量（tensor）；
* 对图像像素做标准化；
 ```python
transform = transforms.Compose([
    transforms.Grayscale(),
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.RandomRotation(degrees=10),
    transforms.Normalize((0.1307,), (0.3081,))
])
```
* 使用 `Adam` 优化器，初始学习率为 0.05；
* 每轮训练后在测试集上评估模型性能，保存最佳模型；
* 使用 `CrossEntropyLoss` 作为损失函数；

最终模型测试准确率可达 98.86%。训练期间提供模型训练日志与准确率输出。

### 3.5 混淆矩阵分析

训练完成后，对模型在测试集上的表现进行混淆矩阵评估。
使用 seaborn 进行可视化分析，如图所示：
![image](https://github.com/user-attachments/assets/223d3549-d757-4f82-b99c-3e64cd225734)



该图展示模型对各数字分类的准确性，有助于定位混淆易发区域。

### 3.6 图形用户界面（GUI）与交互功能（app.py）

GUI 是本项目的重要组成部分，采用 Tkinter 构建，具有以下特点：

* **画板功能**：用户可在画布上手写数字，松开鼠标后系统自动识别内容。
* **图片导入识别**：支持从本地导入图片进行识别，自动缩放并在画布中显示；
* **自动切割与识别**：对于含多个数字的图片或画板书写，调用 `detect_digits_line` 自动进行区域分割与批量识别；
* **现代化界面设计**：按钮样式、颜色配置统一美观，增强用户体验；
* **预测结果展示**：预测结果实时更新在界面下方。

系统在用户完成书写后会自动将画布内容保存为临时图像，并调用识别模块输出预测结果。
![image](https://github.com/user-attachments/assets/0bfa490b-5f5b-483f-b0b3-a096d5e5db12)
![image](https://github.com/user-attachments/assets/7cd9b985-8058-404b-ae9c-c0a22976172d)

## 4. 测试验证

通过以下方式进行了测试：

* **单张图像测试**：对手写数字样本进行多次预测，结果与真实标签高度一致。

* **多数字切割测试**：对多数字图片成功提取各数字，识别顺序正确，精度良好。

* **模型性能**：在MNIST官方测试集准确率98.86%，误识率低。

* **稳定性测试**：GUI操作流畅，预处理和识别速度满足实时需求。

* **扩展测试（摄像头识别）**：尽管受环境影响大，但基本实现了实时识别功能。(函数位于digit_recognition.py 中的capture_and_recognize)

## 5. 总结与创新点

本项目围绕“手写数字识别系统”的设计目标，构建了一个集图像预处理、数字切割、CNN 模型训练与预测、图形用户界面交互等功能于一体的完整识别系统。系统以 PyTorch 深度学习框架为核心，通过对 MNIST 数据集的高效利用，训练出准确率达 98.86% 的卷积神经网络模型，并结合 Tkinter 开发了功能完善、界面友好的图形化操作平台，显著提升了用户体验和系统实用性。

系统功能覆盖从模型训练到多样化识别任务的各个环节，主要优势如下：

- **多场景适应性强**：系统支持单个数字图像识别、多个手写数字图像的自动切割与识别，具备良好的泛化能力；
- **人机交互性优**：GUI 界面支持手写输入与图像导入，操作简洁直观，识别结果实时反馈；
- **识别准确率高**：结合图像增强、二值化、裁剪与数字居中等预处理技术，使模型能在非标准化输入中也能维持较高识别性能；
- **系统运行稳定**：系统在 Windows 平台上稳定运行，图像处理速度快，支持实时绘图识别，整体响应流畅；
- **扩展性良好**：系统中保留了摄像头识别接口，后续可扩展为动态识别版本，满足更复杂的输入场景需求。

### 创新点分析

本项目在传统手写数字识别流程的基础上，结合实际应用需求，设计并实现了如下具有实践价值的创新点：

**创新点：自动数字分割 + 中心归一化 + 实时识别的三阶段联动机制**

该机制整合了 OpenCV 图像处理技术、图像标准化方法与深度学习分类器，使得系统在处理多数字图像时具备如下新特性：

1. **自动轮廓检测与排序**：通过轮廓提取算法自动检测图像中多个数字区域，并依据水平位置排序，从而保持识别结果与人类书写顺序一致；
2. **统一格式归一化**：切割后的每个数字图像自动调整尺寸、增强对比度、进行中心对齐，使其更贴合 MNIST 格式，最大化模型兼容性；
3. **无缝集成与自动识别**：用户在画板中书写或导入图像后，无需点击按钮，系统自动触发预处理、分割与识别流程，实现高效智能的实时识别交互体验。

该机制极大提高了系统对非标准化、多样性输入图像的适应能力和鲁棒性，为实际应用中的批量识别任务提供了技术支撑，尤其适用于自动阅卷、票据识别、智能输入等场景。

### 项目价值与展望

本系统的完成不仅验证了基于深度学习的手写数字识别在工程中的可行性，也展示了 Python + PyTorch + OpenCV + Tkinter 技术栈在实际项目中的整合能力。未来可以在以下几个方面进行扩展与优化：

- **引入更大规模的数据集与数据增强策略**，进一步提高模型泛化能力；
- **增加自适应的噪声处理与斜率校正机制**，优化对复杂手写图像的鲁棒性；
- **接入 Web 服务端或移动端平台**，扩展系统部署范围；
- **支持连续数字字符串的联机识别与语义解析**，拓展模型的自然语言处理边界。



